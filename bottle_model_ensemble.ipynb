{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a439795-3fde-45a5-b9d3-935c26ea6dff",
   "metadata": {},
   "source": [
    "# Estimate uncertainty using model ensemble\n",
    "Created by Ivan Lima on Mon Apr  4 2022 13:29:57 -0400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ad8f30-8f40-45bc-934c-56bd31af2f13",
   "metadata": {},
   "source": [
    "In this notebook we evaluate uncertainty for the model estimates of DIC and TA by training an ensemble of 50 models on the training dataset and using those models to make predictions on the test dataset. Model node weights are randomly initialized dusring model instatiation. Standard deviation is computed for each DIC and TA prediction on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784f760e-9c86-43e0-a3a1-44b65c4052a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated on Mon Apr 18 10:47:54 2022\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime, warnings\n",
    "from tqdm import notebook\n",
    "print('Last updated on {}'.format(datetime.datetime.now().ctime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61a37f3a-708b-4cf1-b6eb-a73847be09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(context='paper', style='ticks', palette='tab10', rc={'figure.dpi':100, 'figure.figsize':[5, 5], 'axes.grid':True})\n",
    "pd.options.display.max_columns = 50\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe737212-55a5-4d31-b942-d1a8acdcd1e2",
   "metadata": {},
   "source": [
    "## Read merged bottle satellite data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d29922-37a0-4960-b18d-34d293637473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3623 entries, 0 to 3779\n",
      "Data columns (total 34 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   EXPOCODE       2488 non-null   object        \n",
      " 1   Accession      1124 non-null   float64       \n",
      " 2   Cruise_ID      3044 non-null   object        \n",
      " 3   Date           3623 non-null   datetime64[ns]\n",
      " 4   Year           3623 non-null   int64         \n",
      " 5   Month          3623 non-null   int64         \n",
      " 6   Day            3623 non-null   int64         \n",
      " 7   Time_UTC       3543 non-null   object        \n",
      " 8   Latitude       3623 non-null   float64       \n",
      " 9   Longitude      3623 non-null   float64       \n",
      " 10  Depth          3623 non-null   float64       \n",
      " 11  Salinity       3623 non-null   float64       \n",
      " 12  Temperature    3623 non-null   float64       \n",
      " 13  Oxygen         3533 non-null   float64       \n",
      " 14  DIC            3623 non-null   float64       \n",
      " 15  DIC_FLAG       3329 non-null   float64       \n",
      " 16  TA             3623 non-null   float64       \n",
      " 17  TA_FLAG        3329 non-null   float64       \n",
      " 18  pCO2_yearave   2600 non-null   float64       \n",
      " 19  pCO2_monthave  3623 non-null   float64       \n",
      " 20  bottom_depth   3623 non-null   float64       \n",
      " 21  ADT            2600 non-null   float64       \n",
      " 22  UGOS           2600 non-null   float64       \n",
      " 23  VGOS           2600 non-null   float64       \n",
      " 24  SLA            3623 non-null   float64       \n",
      " 25  UGOSA          2600 non-null   float64       \n",
      " 26  VGOSA          2600 non-null   float64       \n",
      " 27  SST            3623 non-null   float64       \n",
      " 28  SST_hires      3623 non-null   float64       \n",
      " 29  Chl            3623 non-null   float64       \n",
      " 30  KD490          3623 non-null   float64       \n",
      " 31  outlier        3623 non-null   bool          \n",
      " 32  log_Chl        3623 non-null   float64       \n",
      " 33  log_KD490      3623 non-null   float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(26), int64(3), object(3)\n",
      "memory usage: 965.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/bottle_satellite_data_clean.csv', parse_dates=['Date'], index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409df87-31c4-456b-849d-ac77020ed765",
   "metadata": {},
   "source": [
    "## Select input features and split data into training and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ce92aa2-56dd-467a-aeb9-cb7c522e4b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (2717, 5)\n",
      "Test set: (906, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "# Set input and output variables\n",
    "# features = ['Depth', 'bottom_depth', 'Temperature', 'Salinity', 'Oxygen', 'pCO2_monthave', 'SLA', 'SST_hires', 'log_KD490']\n",
    "# features = ['Depth', 'bottom_depth', 'Temperature', 'Salinity', 'pCO2_monthave', 'SLA', 'SST_hires', 'log_KD490']\n",
    "features = ['Depth', 'bottom_depth', 'Temperature', 'Salinity', 'pCO2_monthave']\n",
    "targets  = ['DIC', 'TA']\n",
    "\n",
    "data = df[features + targets].dropna()\n",
    "\n",
    "X_numpy = data[features].values\n",
    "Y_numpy = data[targets].values\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_numpy_train, X_numpy_test, Y_numpy_train, Y_numpy_test = train_test_split(X_numpy, Y_numpy, random_state=42)\n",
    "\n",
    "print('Training set: {}\\nTest set: {}'.format(X_numpy_train.shape, X_numpy_test.shape))\n",
    "\n",
    "# set suffix for output file names\n",
    "if 'Oxygen' not in features:\n",
    "    if 'SLA' not in features:\n",
    "        suffix = '_no_sat'\n",
    "    else:\n",
    "        suffix = '_noO2'\n",
    "else:\n",
    "    suffix = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a1925-f065-442f-8881-721336708553",
   "metadata": {},
   "source": [
    "## Rescale data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6bb72a-9320-46e0-964a-0aa2bc4784c3",
   "metadata": {},
   "source": [
    "Neural networks are very sensitive to the scale and distribution of each feature. Therefore, we rescale input features so they have $\\overline{x}=0$ and $\\sigma=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ccca66-213e-4937-8858-add2b99b7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_numpy_train)\n",
    "X_numpy_train_scaled = scaler.transform(X_numpy_train)\n",
    "X_numpy_test_scaled = scaler.transform(X_numpy_test)\n",
    "X_numpy_scaled = scaler.transform(X_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a81df-5f49-4fd5-a370-848bfb628aa1",
   "metadata": {},
   "source": [
    "## Run ensemble of models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4b5122-bc4a-4a72-9fbb-5b31c0f536ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8448b6d2a44f63aefcf9cfac4e3a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device\n",
    "\n",
    "# convert numpy arrays to pytorch tensors\n",
    "X_train = torch.from_numpy(X_numpy_train_scaled.astype(np.float32))\n",
    "Y_train = torch.from_numpy(Y_numpy_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_numpy_test_scaled.astype(np.float32))\n",
    "\n",
    "# set neural network parameters\n",
    "n_features = X_train.size()[1] # number of input variables\n",
    "n_targets = Y_train.size()[1]  # number of output variables\n",
    "n_hidden = 256                 # number of hidden layers\n",
    "learning_rate = 0.001\n",
    "\n",
    "# torch.manual_seed(42) # set random number seed to make things reproducible\n",
    "\n",
    "# create neural network regression model\n",
    "class MLPReg(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, n_targets):\n",
    "        super(MLPReg, self).__init__()\n",
    "        self.l1    = nn.Linear(n_features, n_hidden)\n",
    "        self.l2    = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l3    = nn.Linear(n_hidden, n_targets)\n",
    "        self.activ = nn.LeakyReLU()\n",
    "        # nn.init.normal_(self.l1.weight, mean=0.0, std=0.01)\n",
    "        # nn.init.normal_(self.l2.weight, mean=0.0, std=0.01)\n",
    "        # nn.init.normal_(self.l3.weight, mean=0.0, std=0.01)        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.activ(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.activ(out)\n",
    "        out = self.l3(out)\n",
    "        return out\n",
    "\n",
    "loss_func = nn.MSELoss()                                                      # loss function (mean square error)\n",
    "\n",
    "loss_vals = []   # keep loss function values for plotting\n",
    "\n",
    "# store predictions\n",
    "y_train_pred_DIC_list = []\n",
    "y_train_pred_TA_list = []\n",
    "y_test_pred_DIC_list = []\n",
    "y_test_pred_TA_list = []\n",
    "\n",
    "n_passes = 10000\n",
    "\n",
    "def reset_weights(m):\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()\n",
    "\n",
    "for k in notebook.tnrange(50):\n",
    "    # create model instance\n",
    "    nn_reg = MLPReg(n_features=n_features, n_hidden=n_hidden, n_targets=n_targets)\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = torch.optim.Adam(nn_reg.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # reset model weights (not necessary)\n",
    "    # nn_reg.apply(reset_weights)\n",
    "    # for name, param in nn_reg.named_parameters():\n",
    "    #     if name == 'l2.weight':\n",
    "    #         print(name, param)\n",
    "    \n",
    "    # train the model\n",
    "    for n in range(n_passes):\n",
    "        # forward pass\n",
    "        prediction = nn_reg(X_train)\n",
    "        loss = loss_func(prediction, Y_train)\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()   # clear accumulated gradients for next pass\n",
    "        loss.backward()         # do backpropagation to compute gradients\n",
    "        optimizer.step()        # apply gradients to update parameters\n",
    "        loss_vals.append(loss.item())\n",
    "        # if (n==0) or ((n+1) % 1000 == 0):\n",
    "        #     print('pass {:5d}/{}, MSE={:.2f}'.format(n+1, n_passes, loss.item()))\n",
    "\n",
    "    # evaluate model on training & test set\n",
    "    with torch.no_grad():\n",
    "        Y_pred_train = nn_reg(X_train)\n",
    "        Y_pred_test  = nn_reg(X_test)\n",
    "\n",
    "#     print('Ensemble {} training set R squared: {:.3f}'.format(k+1, r2_score(Y_numpy_train, Y_pred_train)))\n",
    "#     print('Ensemble {} test set R squared:     {:.3f}\\n'.format(k+1, r2_score(Y_numpy_test, Y_pred_test)))\n",
    "    \n",
    "    # store predictions on test set\n",
    "    y_train_pred_DIC_list.append(Y_pred_train[:,0].numpy())\n",
    "    y_train_pred_TA_list.append(Y_pred_train[:,1].numpy())\n",
    "    y_test_pred_DIC_list.append(Y_pred_test[:,0].numpy())\n",
    "    y_test_pred_TA_list.append(Y_pred_test[:,1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e87fa5-e827-4e99-956f-719b4c95975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in nn_reg.named_parameters():\n",
    "#     if name == 'l2.weight':\n",
    "#         print(name, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06dab4-d4df-49f0-b756-ff4a9804904a",
   "metadata": {},
   "source": [
    "## Compute standard deviations for DIC and TA predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1560d43-99de-42a9-9a48-384ebc471dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(x):\n",
    "    return pd.Series([x.min(), x.max(), x.median()], index=['min', 'max', 'median'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc7df3-127e-4648-8515-8d4a1d2d4be3",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49ca720d-c059-4adc-9017-c79b6171e7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b321d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b321d_level0_col0\" class=\"col_heading level0 col0\" >std_DIC</th>\n",
       "      <th id=\"T_b321d_level0_col1\" class=\"col_heading level0 col1\" >std_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b321d_level0_row0\" class=\"row_heading level0 row0\" >min</th>\n",
       "      <td id=\"T_b321d_row0_col0\" class=\"data row0 col0\" >1.283</td>\n",
       "      <td id=\"T_b321d_row0_col1\" class=\"data row0 col1\" >0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b321d_level0_row1\" class=\"row_heading level0 row1\" >max</th>\n",
       "      <td id=\"T_b321d_row1_col0\" class=\"data row1 col0\" >14.660</td>\n",
       "      <td id=\"T_b321d_row1_col1\" class=\"data row1 col1\" >10.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b321d_level0_row2\" class=\"row_heading level0 row2\" >median</th>\n",
       "      <td id=\"T_b321d_row2_col0\" class=\"data row2 col0\" >3.252</td>\n",
       "      <td id=\"T_b321d_row2_col1\" class=\"data row2 col1\" >2.550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbef8f4bf40>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_DIC = np.array(y_train_pred_DIC_list).transpose()\n",
    "y_train_pred_TA = np.array(y_train_pred_TA_list).transpose()\n",
    "\n",
    "std_DIC_train = y_train_pred_DIC.std(axis=1)\n",
    "avg_DIC_train = y_train_pred_DIC.mean(axis=1)\n",
    "\n",
    "std_TA_train = y_train_pred_TA.std(axis=1)\n",
    "avg_TA_train = y_train_pred_TA.mean(axis=1)\n",
    "\n",
    "df_std_train = pd.DataFrame({'std_DIC': std_DIC_train, 'std_TA': std_TA_train})\n",
    "df_std_train.apply(minmax).style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae83ec-f3fb-4750-ac68-91afe85badeb",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9e96476a-aa11-4fe3-9153-7a964bfbefd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d9df4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d9df4_level0_col0\" class=\"col_heading level0 col0\" >std_DIC</th>\n",
       "      <th id=\"T_d9df4_level0_col1\" class=\"col_heading level0 col1\" >std_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d9df4_level0_row0\" class=\"row_heading level0 row0\" >min</th>\n",
       "      <td id=\"T_d9df4_row0_col0\" class=\"data row0 col0\" >1.294</td>\n",
       "      <td id=\"T_d9df4_row0_col1\" class=\"data row0 col1\" >0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9df4_level0_row1\" class=\"row_heading level0 row1\" >max</th>\n",
       "      <td id=\"T_d9df4_row1_col0\" class=\"data row1 col0\" >13.091</td>\n",
       "      <td id=\"T_d9df4_row1_col1\" class=\"data row1 col1\" >13.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d9df4_level0_row2\" class=\"row_heading level0 row2\" >median</th>\n",
       "      <td id=\"T_d9df4_row2_col0\" class=\"data row2 col0\" >3.613</td>\n",
       "      <td id=\"T_d9df4_row2_col1\" class=\"data row2 col1\" >2.833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbef9d551c0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_DIC = np.array(y_test_pred_DIC_list).transpose()\n",
    "y_test_pred_TA = np.array(y_test_pred_TA_list).transpose()\n",
    "\n",
    "std_DIC_test = y_test_pred_DIC.std(axis=1)\n",
    "avg_DIC_test = y_test_pred_DIC.mean(axis=1)\n",
    "\n",
    "std_TA_test = y_test_pred_TA.std(axis=1)\n",
    "avg_TA_test = y_test_pred_TA.mean(axis=1)\n",
    "\n",
    "df_std_test = pd.DataFrame({'std_DIC': std_DIC_test, 'std_TA': std_TA_test})\n",
    "df_std_test.apply(minmax).style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93206ea8-6ef3-482c-88c3-5155fe1487c5",
   "metadata": {},
   "source": [
    "### Save computed standard deviations to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48bfea5f-b224-461f-899d-22997ec51f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0892e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0892e_level0_col0\" class=\"col_heading level0 col0\" >Depth</th>\n",
       "      <th id=\"T_0892e_level0_col1\" class=\"col_heading level0 col1\" >bottom_depth</th>\n",
       "      <th id=\"T_0892e_level0_col2\" class=\"col_heading level0 col2\" >Temperature</th>\n",
       "      <th id=\"T_0892e_level0_col3\" class=\"col_heading level0 col3\" >Salinity</th>\n",
       "      <th id=\"T_0892e_level0_col4\" class=\"col_heading level0 col4\" >pCO2_monthave</th>\n",
       "      <th id=\"T_0892e_level0_col5\" class=\"col_heading level0 col5\" >DIC</th>\n",
       "      <th id=\"T_0892e_level0_col6\" class=\"col_heading level0 col6\" >TA</th>\n",
       "      <th id=\"T_0892e_level0_col7\" class=\"col_heading level0 col7\" >std_DIC</th>\n",
       "      <th id=\"T_0892e_level0_col8\" class=\"col_heading level0 col8\" >std_TA</th>\n",
       "      <th id=\"T_0892e_level0_col9\" class=\"col_heading level0 col9\" >avg_DIC</th>\n",
       "      <th id=\"T_0892e_level0_col10\" class=\"col_heading level0 col10\" >avg_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0892e_level0_row0\" class=\"row_heading level0 row0\" >min</th>\n",
       "      <td id=\"T_0892e_row0_col0\" class=\"data row0 col0\" >0.000</td>\n",
       "      <td id=\"T_0892e_row0_col1\" class=\"data row0 col1\" >8.508</td>\n",
       "      <td id=\"T_0892e_row0_col2\" class=\"data row0 col2\" >1.288</td>\n",
       "      <td id=\"T_0892e_row0_col3\" class=\"data row0 col3\" >26.218</td>\n",
       "      <td id=\"T_0892e_row0_col4\" class=\"data row0 col4\" >374.840</td>\n",
       "      <td id=\"T_0892e_row0_col5\" class=\"data row0 col5\" >1748.720</td>\n",
       "      <td id=\"T_0892e_row0_col6\" class=\"data row0 col6\" >1909.760</td>\n",
       "      <td id=\"T_0892e_row0_col7\" class=\"data row0 col7\" >1.283</td>\n",
       "      <td id=\"T_0892e_row0_col8\" class=\"data row0 col8\" >0.771</td>\n",
       "      <td id=\"T_0892e_row0_col9\" class=\"data row0 col9\" >1782.446</td>\n",
       "      <td id=\"T_0892e_row0_col10\" class=\"data row0 col10\" >1924.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0892e_level0_row1\" class=\"row_heading level0 row1\" >max</th>\n",
       "      <td id=\"T_0892e_row1_col0\" class=\"data row1 col0\" >2200.652</td>\n",
       "      <td id=\"T_0892e_row1_col1\" class=\"data row1 col1\" >4587.000</td>\n",
       "      <td id=\"T_0892e_row1_col2\" class=\"data row1 col2\" >29.553</td>\n",
       "      <td id=\"T_0892e_row1_col3\" class=\"data row1 col3\" >36.798</td>\n",
       "      <td id=\"T_0892e_row1_col4\" class=\"data row1 col4\" >414.860</td>\n",
       "      <td id=\"T_0892e_row1_col5\" class=\"data row1 col5\" >2215.170</td>\n",
       "      <td id=\"T_0892e_row1_col6\" class=\"data row1 col6\" >2407.880</td>\n",
       "      <td id=\"T_0892e_row1_col7\" class=\"data row1 col7\" >14.660</td>\n",
       "      <td id=\"T_0892e_row1_col8\" class=\"data row1 col8\" >10.847</td>\n",
       "      <td id=\"T_0892e_row1_col9\" class=\"data row1 col9\" >2205.630</td>\n",
       "      <td id=\"T_0892e_row1_col10\" class=\"data row1 col10\" >2413.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0892e_level0_row2\" class=\"row_heading level0 row2\" >median</th>\n",
       "      <td id=\"T_0892e_row2_col0\" class=\"data row2 col0\" >38.285</td>\n",
       "      <td id=\"T_0892e_row2_col1\" class=\"data row2 col1\" >131.000</td>\n",
       "      <td id=\"T_0892e_row2_col2\" class=\"data row2 col2\" >11.138</td>\n",
       "      <td id=\"T_0892e_row2_col3\" class=\"data row2 col3\" >33.310</td>\n",
       "      <td id=\"T_0892e_row2_col4\" class=\"data row2 col4\" >404.150</td>\n",
       "      <td id=\"T_0892e_row2_col5\" class=\"data row2 col5\" >2069.560</td>\n",
       "      <td id=\"T_0892e_row2_col6\" class=\"data row2 col6\" >2237.600</td>\n",
       "      <td id=\"T_0892e_row2_col7\" class=\"data row2 col7\" >3.252</td>\n",
       "      <td id=\"T_0892e_row2_col8\" class=\"data row2 col8\" >2.550</td>\n",
       "      <td id=\"T_0892e_row2_col9\" class=\"data row2 col9\" >2068.117</td>\n",
       "      <td id=\"T_0892e_row2_col10\" class=\"data row2 col10\" >2238.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbefa18fd30>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile_train =  'data/uncertainty_trainset{}.csv'.format(suffix)\n",
    "df_train = pd.DataFrame(np.c_[X_numpy_train, Y_numpy_train], columns = features + targets)\n",
    "df_train['std_DIC'] = std_DIC_train\n",
    "df_train['std_TA'] = std_TA_train\n",
    "df_train['avg_DIC'] = avg_DIC_train\n",
    "df_train['avg_TA'] = avg_TA_train\n",
    "df_train.to_csv(outfile_train) # save stats to csv file\n",
    "df_train.apply(minmax).style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52f3c823-9a67-4c5b-b6ab-5b5cd71fcc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_040ab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_040ab_level0_col0\" class=\"col_heading level0 col0\" >Depth</th>\n",
       "      <th id=\"T_040ab_level0_col1\" class=\"col_heading level0 col1\" >bottom_depth</th>\n",
       "      <th id=\"T_040ab_level0_col2\" class=\"col_heading level0 col2\" >Temperature</th>\n",
       "      <th id=\"T_040ab_level0_col3\" class=\"col_heading level0 col3\" >Salinity</th>\n",
       "      <th id=\"T_040ab_level0_col4\" class=\"col_heading level0 col4\" >pCO2_monthave</th>\n",
       "      <th id=\"T_040ab_level0_col5\" class=\"col_heading level0 col5\" >DIC</th>\n",
       "      <th id=\"T_040ab_level0_col6\" class=\"col_heading level0 col6\" >TA</th>\n",
       "      <th id=\"T_040ab_level0_col7\" class=\"col_heading level0 col7\" >std_DIC</th>\n",
       "      <th id=\"T_040ab_level0_col8\" class=\"col_heading level0 col8\" >std_TA</th>\n",
       "      <th id=\"T_040ab_level0_col9\" class=\"col_heading level0 col9\" >avg_DIC</th>\n",
       "      <th id=\"T_040ab_level0_col10\" class=\"col_heading level0 col10\" >avg_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_040ab_level0_row0\" class=\"row_heading level0 row0\" >min</th>\n",
       "      <td id=\"T_040ab_row0_col0\" class=\"data row0 col0\" >0.000</td>\n",
       "      <td id=\"T_040ab_row0_col1\" class=\"data row0 col1\" >8.508</td>\n",
       "      <td id=\"T_040ab_row0_col2\" class=\"data row0 col2\" >2.880</td>\n",
       "      <td id=\"T_040ab_row0_col3\" class=\"data row0 col3\" >26.266</td>\n",
       "      <td id=\"T_040ab_row0_col4\" class=\"data row0 col4\" >382.240</td>\n",
       "      <td id=\"T_040ab_row0_col5\" class=\"data row0 col5\" >1784.830</td>\n",
       "      <td id=\"T_040ab_row0_col6\" class=\"data row0 col6\" >1916.933</td>\n",
       "      <td id=\"T_040ab_row0_col7\" class=\"data row0 col7\" >1.294</td>\n",
       "      <td id=\"T_040ab_row0_col8\" class=\"data row0 col8\" >0.789</td>\n",
       "      <td id=\"T_040ab_row0_col9\" class=\"data row0 col9\" >1823.020</td>\n",
       "      <td id=\"T_040ab_row0_col10\" class=\"data row0 col10\" >1926.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_040ab_level0_row1\" class=\"row_heading level0 row1\" >max</th>\n",
       "      <td id=\"T_040ab_row1_col0\" class=\"data row1 col0\" >1499.557</td>\n",
       "      <td id=\"T_040ab_row1_col1\" class=\"data row1 col1\" >4587.000</td>\n",
       "      <td id=\"T_040ab_row1_col2\" class=\"data row1 col2\" >29.515</td>\n",
       "      <td id=\"T_040ab_row1_col3\" class=\"data row1 col3\" >36.743</td>\n",
       "      <td id=\"T_040ab_row1_col4\" class=\"data row1 col4\" >414.860</td>\n",
       "      <td id=\"T_040ab_row1_col5\" class=\"data row1 col5\" >2233.891</td>\n",
       "      <td id=\"T_040ab_row1_col6\" class=\"data row1 col6\" >2402.900</td>\n",
       "      <td id=\"T_040ab_row1_col7\" class=\"data row1 col7\" >13.091</td>\n",
       "      <td id=\"T_040ab_row1_col8\" class=\"data row1 col8\" >13.527</td>\n",
       "      <td id=\"T_040ab_row1_col9\" class=\"data row1 col9\" >2206.837</td>\n",
       "      <td id=\"T_040ab_row1_col10\" class=\"data row1 col10\" >2412.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_040ab_level0_row2\" class=\"row_heading level0 row2\" >median</th>\n",
       "      <td id=\"T_040ab_row2_col0\" class=\"data row2 col0\" >40.000</td>\n",
       "      <td id=\"T_040ab_row2_col1\" class=\"data row2 col1\" >131.000</td>\n",
       "      <td id=\"T_040ab_row2_col2\" class=\"data row2 col2\" >11.234</td>\n",
       "      <td id=\"T_040ab_row2_col3\" class=\"data row2 col3\" >33.482</td>\n",
       "      <td id=\"T_040ab_row2_col4\" class=\"data row2 col4\" >403.340</td>\n",
       "      <td id=\"T_040ab_row2_col5\" class=\"data row2 col5\" >2070.500</td>\n",
       "      <td id=\"T_040ab_row2_col6\" class=\"data row2 col6\" >2242.550</td>\n",
       "      <td id=\"T_040ab_row2_col7\" class=\"data row2 col7\" >3.613</td>\n",
       "      <td id=\"T_040ab_row2_col8\" class=\"data row2 col8\" >2.833</td>\n",
       "      <td id=\"T_040ab_row2_col9\" class=\"data row2 col9\" >2069.708</td>\n",
       "      <td id=\"T_040ab_row2_col10\" class=\"data row2 col10\" >2242.181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbef8f41880>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfile_test =  'data/uncertainty_testset{}.csv'.format(suffix)\n",
    "df_test = pd.DataFrame(np.c_[X_numpy_test, Y_numpy_test], columns = features + targets)\n",
    "df_test['std_DIC'] = std_DIC_test\n",
    "df_test['std_TA'] = std_TA_test\n",
    "df_test['avg_DIC'] = avg_DIC_test\n",
    "df_test['avg_TA'] = avg_TA_test\n",
    "df_test.to_csv(outfile_test) # save stats to csv file\n",
    "df_test.apply(minmax).style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6575fe5d-07af-4092-b38e-53d42721ab85",
   "metadata": {},
   "source": [
    "## Compute $R^2$ and RMSE for each ensemble member "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde323f8-4f0c-41b6-b22b-6d3f9ddc1e23",
   "metadata": {},
   "source": [
    "### Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a07f9e46-77c9-45b1-9f6e-0735eedb717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b0617\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b0617_level0_col0\" class=\"col_heading level0 col0\" >r2_DIC</th>\n",
       "      <th id=\"T_b0617_level0_col1\" class=\"col_heading level0 col1\" >rmse_DIC</th>\n",
       "      <th id=\"T_b0617_level0_col2\" class=\"col_heading level0 col2\" >r2_TA</th>\n",
       "      <th id=\"T_b0617_level0_col3\" class=\"col_heading level0 col3\" >rmse_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b0617_level0_row0\" class=\"row_heading level0 row0\" >min</th>\n",
       "      <td id=\"T_b0617_row0_col0\" class=\"data row0 col0\" >0.943</td>\n",
       "      <td id=\"T_b0617_row0_col1\" class=\"data row0 col1\" >15.338</td>\n",
       "      <td id=\"T_b0617_row0_col2\" class=\"data row0 col2\" >0.985</td>\n",
       "      <td id=\"T_b0617_row0_col3\" class=\"data row0 col3\" >7.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0617_level0_row1\" class=\"row_heading level0 row1\" >max</th>\n",
       "      <td id=\"T_b0617_row1_col0\" class=\"data row1 col0\" >0.958</td>\n",
       "      <td id=\"T_b0617_row1_col1\" class=\"data row1 col1\" >17.821</td>\n",
       "      <td id=\"T_b0617_row1_col2\" class=\"data row1 col2\" >0.988</td>\n",
       "      <td id=\"T_b0617_row1_col3\" class=\"data row1 col3\" >9.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0617_level0_row2\" class=\"row_heading level0 row2\" >median</th>\n",
       "      <td id=\"T_b0617_row2_col0\" class=\"data row2 col0\" >0.952</td>\n",
       "      <td id=\"T_b0617_row2_col1\" class=\"data row2 col1\" >16.322</td>\n",
       "      <td id=\"T_b0617_row2_col2\" class=\"data row2 col2\" >0.987</td>\n",
       "      <td id=\"T_b0617_row2_col3\" class=\"data row2 col3\" >8.444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbefa18f5b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_out_train =  'data/ensemble_trainset{}.csv'.format(suffix)\n",
    "\n",
    "dic_r2_train = [r2_score(Y_numpy_train[:,0], y_train_pred_DIC[:,c]) for c in range(y_train_pred_DIC.shape[1])]\n",
    "ta_r2_train  = [r2_score(Y_numpy_train[:,1], y_train_pred_TA[:,c]) for c in range(y_train_pred_TA.shape[1])]\n",
    "dic_rmse_train = [mean_squared_error(Y_numpy_train[:,0], y_train_pred_DIC[:,c], squared=False) for c in range(y_train_pred_DIC.shape[1])]\n",
    "ta_rmse_train  = [mean_squared_error(Y_numpy_train[:,1], y_train_pred_TA[:,c], squared=False) for c in range(y_train_pred_TA.shape[1])]\n",
    "\n",
    "df_ensemble_train = pd.DataFrame({'r2_DIC': dic_r2_train, 'rmse_DIC': dic_rmse_train, 'r2_TA': ta_r2_train, 'rmse_TA': ta_rmse_train})\n",
    "df_ensemble_train.to_csv(ens_out_train)\n",
    "df_ensemble_train.apply(minmax).style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48755926-1672-4536-9552-467c6d8bf5c3",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cee6a7b5-36c7-4d11-95c5-1f4210e6dd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_63923\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_63923_level0_col0\" class=\"col_heading level0 col0\" >r2_DIC</th>\n",
       "      <th id=\"T_63923_level0_col1\" class=\"col_heading level0 col1\" >rmse_DIC</th>\n",
       "      <th id=\"T_63923_level0_col2\" class=\"col_heading level0 col2\" >r2_TA</th>\n",
       "      <th id=\"T_63923_level0_col3\" class=\"col_heading level0 col3\" >rmse_TA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_63923_level0_row0\" class=\"row_heading level0 row0\" >min</th>\n",
       "      <td id=\"T_63923_row0_col0\" class=\"data row0 col0\" >0.941</td>\n",
       "      <td id=\"T_63923_row0_col1\" class=\"data row0 col1\" >16.489</td>\n",
       "      <td id=\"T_63923_row0_col2\" class=\"data row0 col2\" >0.981</td>\n",
       "      <td id=\"T_63923_row0_col3\" class=\"data row0 col3\" >8.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63923_level0_row1\" class=\"row_heading level0 row1\" >max</th>\n",
       "      <td id=\"T_63923_row1_col0\" class=\"data row1 col0\" >0.950</td>\n",
       "      <td id=\"T_63923_row1_col1\" class=\"data row1 col1\" >17.807</td>\n",
       "      <td id=\"T_63923_row1_col2\" class=\"data row1 col2\" >0.986</td>\n",
       "      <td id=\"T_63923_row1_col3\" class=\"data row1 col3\" >10.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_63923_level0_row2\" class=\"row_heading level0 row2\" >median</th>\n",
       "      <td id=\"T_63923_row2_col0\" class=\"data row2 col0\" >0.946</td>\n",
       "      <td id=\"T_63923_row2_col1\" class=\"data row2 col1\" >17.117</td>\n",
       "      <td id=\"T_63923_row2_col2\" class=\"data row2 col2\" >0.984</td>\n",
       "      <td id=\"T_63923_row2_col3\" class=\"data row2 col3\" >9.539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbef9d6a790>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_out_test =  'data/ensemble_testset{}.csv'.format(suffix)\n",
    "\n",
    "dic_r2_test = [r2_score(Y_numpy_test[:,0], y_test_pred_DIC[:,c]) for c in range(y_test_pred_DIC.shape[1])]\n",
    "ta_r2_test  = [r2_score(Y_numpy_test[:,1], y_test_pred_TA[:,c]) for c in range(y_test_pred_TA.shape[1])]\n",
    "dic_rmse_test = [mean_squared_error(Y_numpy_test[:,0], y_test_pred_DIC[:,c], squared=False) for c in range(y_test_pred_DIC.shape[1])]\n",
    "ta_rmse_test  = [mean_squared_error(Y_numpy_test[:,1], y_test_pred_TA[:,c], squared=False) for c in range(y_test_pred_TA.shape[1])]\n",
    "\n",
    "df_ensemble_test = pd.DataFrame({'r2_DIC': dic_r2_test, 'rmse_DIC': dic_rmse_test, 'r2_TA': ta_r2_test, 'rmse_TA': ta_rmse_test})\n",
    "df_ensemble_test.to_csv(ens_out_test)\n",
    "df_ensemble_test.apply(minmax).style.format('{:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0e93daee01b8411a9c4f2ec6166681ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0fc92c73f9a94ddd979823d0d3c83b90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1b75777345fc4a8c83bda39576e0f82d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_56dd3c4b4361482895bf533656ba6274",
       "style": "IPY_MODEL_5adb6e27380a493c8738b8a2274fe95a",
       "value": " 50/50 [41:35&lt;00:00, 48.51s/it]"
      }
     },
     "1f8448b6d2a44f63aefcf9cfac4e3a3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_842f1c77207e4c878920c0b43ff17388",
        "IPY_MODEL_75788e7cbeed4e42a533492d15e3b9aa",
        "IPY_MODEL_1b75777345fc4a8c83bda39576e0f82d"
       ],
       "layout": "IPY_MODEL_0fc92c73f9a94ddd979823d0d3c83b90"
      }
     },
     "56dd3c4b4361482895bf533656ba6274": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5adb6e27380a493c8738b8a2274fe95a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "75788e7cbeed4e42a533492d15e3b9aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_e0b915d623e24f7caecdf4700a15860e",
       "max": 50,
       "style": "IPY_MODEL_f8c9e057ac2845388e4152853bb96163",
       "value": 50
      }
     },
     "842f1c77207e4c878920c0b43ff17388": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_95832cc40009431492d260b5ceac676f",
       "style": "IPY_MODEL_0e93daee01b8411a9c4f2ec6166681ec",
       "value": "100%"
      }
     },
     "95832cc40009431492d260b5ceac676f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e0b915d623e24f7caecdf4700a15860e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f8c9e057ac2845388e4152853bb96163": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
