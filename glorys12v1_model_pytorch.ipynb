{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85407f2e-46fd-40a8-badb-e327fb94034d",
   "metadata": {},
   "source": [
    "# Apply neural network model to GLORYS12V1 daily data\n",
    "Created by Ivan Lima on Fri May  6 2022 15:34:42 -0400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762dd13-92f4-458f-8af2-d8af1c5ceeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime\n",
    "from tqdm import notebook\n",
    "print('Last updated on {}'.format(datetime.datetime.now().ctime()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe47f5-1ca4-45fb-bda7-13b9cc7cb0b9",
   "metadata": {},
   "source": [
    "## Load neural network model and data scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e389db-51a4-440f-ae7d-d5c457258a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, joblib\n",
    "import torch.nn as nn\n",
    "\n",
    "scaler = joblib.load('models/scaler_nosat.joblib')\n",
    "\n",
    "features = ['depth', 'bottom_depth', 'Temperature', 'Salinity', 'pCO2_monthave']\n",
    "\n",
    "n_features = len(features) # number of input variables\n",
    "n_targets = 2  # number of output variables\n",
    "n_hidden = 256 # number of hidden layers\n",
    "learning_rate = 0.001\n",
    "\n",
    "class MLPReg(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, n_targets):\n",
    "        super(MLPReg, self).__init__()\n",
    "        self.l1    = nn.Linear(n_features, n_hidden)\n",
    "        self.l2    = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l3    = nn.Linear(n_hidden, n_targets)\n",
    "        self.activ = nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.activ(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.activ(out)\n",
    "        out = self.l3(out)\n",
    "        return out\n",
    "\n",
    "nn_reg = MLPReg(n_features=n_features, n_hidden=n_hidden, n_targets=n_targets) # create model instance\n",
    "loss_func = nn.MSELoss()                                                       # loss function (mean square error)\n",
    "optimizer = torch.optim.Adam(nn_reg.parameters(), lr=learning_rate)            # optimizer\n",
    "\n",
    "nn_reg.load_state_dict(torch.load('models/nn_reg_nosat_state.pth'))\n",
    "nn_reg.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51da3627-ce0a-44be-9e79-830aded2862e",
   "metadata": {},
   "source": [
    "## Extract bottom depth at grid points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26207d8c-f245-4c79-9c13-673aeba75d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "ds_grid = xr.open_dataset('/bali/data/ilima/GLORYS12V1/daily/GLORYS12V1_NW_Atlantic_1993_daily.nc',\n",
    "                          drop_variables = ['mlotst','zos','bottomT'])\n",
    "\n",
    "xx, yy = np.meshgrid(ds_grid.longitude.values, ds_grid.latitude.values)\n",
    "df_positions = pd.DataFrame({'longitude': xx.ravel(), 'latitude': yy.ravel()})\n",
    "\n",
    "# read bottom topography data\n",
    "etopo = xr.open_dataset('data/etopo5.nc', chunks='auto')\n",
    "# etopo['bath'] = etopo.bath.where(etopo.bath<0) # ocean points only\n",
    "etopo = etopo.isel(X=slice(3100,4000), Y=slice(1300,1700)) # subset data to make things faster\n",
    "\n",
    "X = np.where(etopo.X>180, etopo.X-360, etopo.X) # 0:360 -> -180:180\n",
    "lon_topo, lat_topo = np.meshgrid(X, etopo.Y.values)\n",
    "lon, lat = df_positions.longitude.values, df_positions.latitude.values\n",
    "bottom_depth = griddata((lon_topo.ravel(), lat_topo.ravel()), etopo.bath.values.ravel(), (lon, lat), method='linear')\n",
    "df_positions['bottom_depth'] = np.abs(bottom_depth)\n",
    "print(df_positions.bottom_depth.min(), df_positions.bottom_depth.max())\n",
    "df_positions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979a1176-da86-49b4-b01a-7dbe518d4838",
   "metadata": {},
   "source": [
    "## Read monthly atmospheric pCO2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf4a12-923c-4ffe-b281-f2475aa65068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pco2_monthly = pd.read_csv('work/co2_mm_mlo.csv')\n",
    "df_pco2_monthly = df_pco2_monthly.set_index(['year','month'])\n",
    "\n",
    "# for i in df_pco2_monthly.loc[2016].index:\n",
    "#     print(i, df_pco2_monthly.loc[(2016,i),'average'])\n",
    "# atm_pco2 = [df_pco2_monthly.loc[(2016,i),'average'] for i in ds.time.dt.month.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9af85f-75ce-4bdd-8fba-5df7b3bf9f07",
   "metadata": {},
   "source": [
    "## Apply NN model to GLORYS12V1 data and compute carbonate chemistry variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5b9872-3cd8-4e13-8055-0ab3a5a947f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyCO2SYS as pyco2\n",
    "import gsw\n",
    "\n",
    "cols = ['time', 'longitude', 'latitude', 'depth', 'bottom_depth', 'Temperature', 'Salinity', 'pCO2_monthave']\n",
    "\n",
    "year = 2019\n",
    "ds_in = xr.open_dataset('/bali/data/ilima/GLORYS12V1/daily/GLORYS12V1_NW_Atlantic_{}_daily.nc'.format(year),\n",
    "                        drop_variables = ['mlotst','zos','bottomT'])\n",
    "ds_out = [] # store list of datasets\n",
    "\n",
    "for t in notebook.tqdm(range(ds_in.dims['time'])):\n",
    "    ds = ds_in.isel(time=t)\n",
    "\n",
    "    # add monthly atmospheric pCO2\n",
    "    for i in df_pco2_monthly.loc[year].index:\n",
    "        if i==1:\n",
    "            fill = np.nan\n",
    "        else:\n",
    "            fill = ds.pCO2_monthave\n",
    "\n",
    "        ds['pCO2_monthave'] = xr.where(ds.time.dt.month==i, df_pco2_monthly.loc[(2016,i),'average'], fill)\n",
    "\n",
    "\n",
    "    # merge bottom depth with GLORYS12V1 data\n",
    "    df_glorys = ds[['pCO2_monthave','thetao','so']].to_dataframe()\n",
    "    df_glorys = df_glorys.reset_index().rename(columns={'thetao':'Temperature', 'so':'Salinity'})\n",
    "    df_glorys = pd.merge(df_positions, df_glorys, on=['longitude', 'latitude'])\n",
    "    df_data = df_glorys[cols].dropna()\n",
    "    # print('{:,d} data points\\n'.format(df_data.shape[0]))\n",
    "\n",
    "    X_numpy = df_data[features].values # select features\n",
    "    X_numpy_scaled = scaler.transform(X_numpy) # rescale features\n",
    "    X = torch.from_numpy(X_numpy_scaled.astype(np.float32)) # convert array to tensor\n",
    "\n",
    "    # apply model to rescaled features\n",
    "    with torch.no_grad():\n",
    "        Y_pred = nn_reg(X)\n",
    "\n",
    "    # add estimated DIC & TA to features dataframe\n",
    "    df_data['DIC'] = Y_pred[:,0]\n",
    "    df_data['TA'] = Y_pred[:,1]\n",
    "\n",
    "    # compute additional carbonate chemistry variables\n",
    "    pressure =  gsw.p_from_z(-df_data.depth.values, df_data.latitude.values)\n",
    "    kwargs = dict(\n",
    "        par1 = df_data.TA.values,   # TA\n",
    "        par2 = df_data.DIC.values,  # DIC\n",
    "        par1_type = 1,             # type 1 = alkalinity\n",
    "        par2_type = 2,             # type 2 = DIC\n",
    "        salinity = df_data.Salinity.values,\n",
    "        temperature = df_data.Temperature.values,\n",
    "        pressure = pressure,\n",
    "        opt_k_carbonic = 10,  # LDK00, Lueker et al 2000\n",
    "        opt_k_bisulfate = 1,  # D90a, Dickson 1990\n",
    "        opt_total_borate = 2, # LKB10, Lee et al 2010\n",
    "        opt_k_fluoride = 2    # PF87, Perez & Fraga 1987\n",
    "    )\n",
    "    results = pyco2.sys(**kwargs)\n",
    "    co2sys_vars = ['pH', 'saturation_calcite', 'saturation_aragonite']\n",
    "    for vname in co2sys_vars:\n",
    "        df_data[vname] = results[vname]\n",
    "    \n",
    "    # merge estimated carbonate chemistry variables to original dataframe\n",
    "    for vname in ['DIC','TA'] + co2sys_vars:\n",
    "        df_glorys[vname] = df_data[vname]\n",
    "\n",
    "    # convert dataframe to xarray dataset\n",
    "    df = df_glorys.set_index(['time','depth','latitude','longitude'])\n",
    "    ds_bgc = df[['Temperature', 'Salinity', 'DIC', 'TA','pH', 'saturation_calcite', 'saturation_aragonite']].to_xarray()\n",
    "\n",
    "    ds_out.append(ds_bgc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f90e8-6b2a-4754-b10c-4ac36ad59b23",
   "metadata": {},
   "source": [
    "## Create output dataset including T, S, DIC & TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd3420-6465-46cd-a815-eb6422d6188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_attrs = {\n",
    "    'DIC': {'long_name': 'Dissolved inorganic carbon',\n",
    "            'standard_name': 'DIC',\n",
    "            'units': 'micro mol/kg',\n",
    "            'unit_long': 'micro mol/kg'},\n",
    "    'TA': {'long_name': 'Total alkalinity',\n",
    "            'standard_name': 'TA',\n",
    "            'units': 'micro mol/kg',\n",
    "            'unit_long': 'micro mol/kg'},\n",
    "    'pH': {'long_name': 'Total pH',\n",
    "            'standard_name': 'pH',\n",
    "            'units': '',\n",
    "            'unit_long': ''},\n",
    "    'saturation_calcite': {'long_name': 'Calcite saturation state',\n",
    "            'standard_name': 'Calcite saturation',\n",
    "            'units': '',\n",
    "            'unit_long': ''},\n",
    "    'saturation_aragonite': {'long_name': 'Aragonite saturation state',\n",
    "            'standard_name': 'Aragonite saturation',\n",
    "            'units': '',\n",
    "            'unit_long': ''},\n",
    "}\n",
    "\n",
    "ds_out = xr.concat(ds_out, dim='time')\n",
    "\n",
    "# copy variable attributes\n",
    "for vname in var_attrs:\n",
    "    ds_out[vname].attrs.update(var_attrs[vname])\n",
    "for attr in ['long_name','standard_name','units','unit_long']:\n",
    "    ds_out.Temperature.attrs[attr] = ds.thetao.attrs[attr]\n",
    "    ds_out.Salinity.attrs[attr] = ds.so.attrs[attr]\n",
    "    for vname in ['depth','latitude','longitude']:\n",
    "        ds_out[vname].attrs[attr] = ds[vname].attrs[attr]\n",
    "\n",
    "now = datetime.datetime.now().ctime()\n",
    "attrs={'contents':'Estimated carbonate chemistry variables for GLORYS12V1 output',\n",
    "       'history':'Created by Ivan Lima <ilima@whoi.edu> on {}'.format(now)}\n",
    "ds_out.attrs.update(attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf19dde-7c3a-4a0c-b1fa-70b1452a235b",
   "metadata": {},
   "source": [
    "## Save data into monthly files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb39d615-3d19-4bc5-b7fb-a53b39fad6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '/bali/data/ilima/GLORYS12V1/daily/BGC/3D'\n",
    "for mon in range(1,13):\n",
    "    outfile = os.path.join(outdir, 'GLORYS12V1_NW_Atlantic_{}-{:02d}_BGC.nc'.format(year, mon))\n",
    "    ds_month = ds_out.sel(time=ds_out.time.dt.month.isin([mon]))\n",
    "    print('writing {}'.format(outfile))\n",
    "    ds_month.to_netcdf(outfile, mode='w', unlimited_dims=['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26fc62-074b-4336-9c51-49cdb1c568d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_out.to_netcdf('test.nc', mode='w', unlimited_dims=['time'])#, encoding={'zlib': True, 'complevel': 9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd85872-c815-46dd-b2ed-381ea324a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = 366/2\n",
    "# fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(15, 10))\n",
    "# _ = ds_out.Temperature.isel(time=t, depth=0).plot(ax=axs[0,0])\n",
    "# _ = ds_out.Salinity.isel(time=t, depth=0).plot(ax=axs[0,1], robust=True)\n",
    "# _ = ds_out.DIC.isel(time=t, depth=0).plot(ax=axs[0,2], robust=True)\n",
    "# _ = ds_out.TA.isel(time=t, depth=0).plot(ax=axs[1,0], robust=True)\n",
    "# _ = ds_out.pH.isel(time=t, depth=0).plot(ax=axs[1,1], robust=True)\n",
    "# _ = ds_out.saturation_aragonite.isel(time=t, depth=0).plot(ax=axs[1,2], robust=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
